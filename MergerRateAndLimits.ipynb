{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "from scipy.integrate import odeint\n",
    "from scipy.special import erf\n",
    "from scipy.integrate import quad, dblquad\n",
    "from scipy.interpolate import interp1d,interp2d,RectBivariateSpline, griddata\n",
    "\n",
    "import emcee\n",
    "\n",
    "#----- MATPLOTLIB paramaters ---------\n",
    "mpl.rcParams.update({'font.size': 18,'font.family':'sans-serif'})\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 7\n",
    "mpl.rcParams['xtick.major.width'] = 1\n",
    "mpl.rcParams['xtick.minor.size'] = 3\n",
    "mpl.rcParams['xtick.minor.width'] = 1\n",
    "mpl.rcParams['ytick.major.size'] = 7\n",
    "mpl.rcParams['ytick.major.width'] = 1\n",
    "mpl.rcParams['ytick.minor.size'] = 3\n",
    "mpl.rcParams['ytick.minor.width'] = 1\n",
    "#--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_N = 4.302e-3 #(pc/solar mass) (km/s)^2\n",
    "G_N_Mpc = 1e-6*4.302e-3 #(Mpc/solar mass) (km/s)^2\n",
    "\n",
    "h = 0.678\n",
    "Omega_DM = 0.1186/(h**2)\n",
    "H0 = 100.0*h #(km/s) Mpc^-1\n",
    "H0_peryr = 67.8*(3.24e-20)*(60*60*24*365)\n",
    "ageUniverse = 13.799e9 #y\n",
    "Omega_L = 0.692\n",
    "Omega_m = 0.308\n",
    "Omega_r = 9.3e-5\n",
    "\n",
    "z_eq = 3375.0\n",
    "rho_eq = 1512.0 #Solar masses per pc^3\n",
    "sigma_eq = 0.005 #Variance of DM density perturbations at equality\n",
    "lambda_max = 3.0\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "rtr_interp = None\n",
    "Ubind_interp = None\n",
    "current_MPBH = -10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Several useful functions that provide truncation radius, mass of accreted DM halo, decoupling redshift\n",
    "\n",
    "#M_PBH in solar masses\n",
    "\n",
    "def r_trunc(z, M_PBH):\n",
    "    r0 = 6.3e-3 #1300 AU in pc\n",
    "    return r0*(M_PBH)**(1.0/3.0)*(1.+z_eq)/(1.+z)\n",
    "\n",
    "#Truncation radiation at equality\n",
    "def r_eq(M_PBH):\n",
    "    return r_trunc(z_eq, M_PBH)\n",
    "\n",
    "#DM Halo mass\n",
    "def M_halo(z, M_PBH):\n",
    "    return M_PBH*(r_trunc(z, M_PBH)/r_eq(M_PBH))**1.5\n",
    "\n",
    "def xbar(f, M_PBH):\n",
    "    return (3.0*M_PBH/(4*np.pi*rho_eq*(0.85*f)))**(1.0/3.0)\n",
    "\n",
    "def semimajoraxis(z_pair, f, M_PBH):\n",
    "    Mtot = M_PBH\n",
    "    X = 3.0*z_eq*0.85*f/z_pair\n",
    "    return alpha*xbar(f, M_PBH)*(f*0.85)**(1.0/3.0)*((X/(0.85*f))**(4.0/3.0))\n",
    "\n",
    "def semimajoraxis_full(z_pair, f, M_PBH):\n",
    "    Mtot = M_PBH + M_halo(z_pair, M_PBH)\n",
    "    X = 3.0*z_eq*0.85*f/z_pair\n",
    "    return alpha*xbar(f, Mtot)*(f*0.85)**(1.0/3.0)*((X/(0.85*f))**(4.0/3.0))\n",
    "\n",
    "def bigX(x, f, M_PBH):\n",
    "    return (x/(xbar(f,M_PBH)))**3.0\n",
    "\n",
    "def x_of_a(a, f, M_PBH, withHalo = False):\n",
    "    \n",
    "    xb = xbar(f, M_PBH)\n",
    "    \n",
    "    if (not withHalo):        \n",
    "        return ((a * (0.85*f) * xb**3)/alpha)**(1.0/4.0)\n",
    "    \n",
    "    elif (withHalo):                                                              \n",
    "        xb_rescaled = xb * ((M_PBH + M_halo(a, M_PBH))/M_PBH )**(1./3.)            \n",
    "        return ((a * (0.85*f) * xb_rescaled**3)/alpha)**(1.0/4.0)\n",
    "\n",
    "def a_of_x(x, f, M_PBH):\n",
    "    \n",
    "    xb = xbar(f, M_PBH)\n",
    "    return (alpha/(0.85*f))*x**4/xb**3    \n",
    "        \n",
    "def z_decoupling(a, f, mass):\n",
    "    return (1. + z_eq)/(1./3 * bigX(x_of_a(a, f, mass), f, mass)/(0.85*f)) - 1.\n",
    "\n",
    "def a_max(f, M_PBH):\n",
    "    return alpha*xbar(f, M_PBH)*(f*0.85)**(1.0/3.0)*((lambda_max)**(4.0/3.0))\n",
    "\n",
    "def a_max_with_Halo(f, M_PBH):\n",
    "    return alpha*xbar(f, 2.*M_PBH)*(f*0.85)**(1.0/3.0)*((lambda_max)**(4.0/3.0))\n",
    "\n",
    "def GetRtrInterp(f, M_PBH):\n",
    "    \n",
    "    global rtr_interp\n",
    "    \n",
    "    am = a_max_with_Halo(f, M_PBH)\n",
    "    a_list = np.logspace(-9, np.log10(am*1.2), 101)\n",
    "\n",
    "    z_decoupling_0 = z_decoupling(a_list, f, M_PBH)\n",
    "    M_halo_0 = M_halo(z_decoupling_0, M_PBH)\n",
    "\n",
    "    z_decoupling_1 = np.zeros(len(a_list))\n",
    "    M_halo_1 = np.zeros(len(a_list))\n",
    "    for i in range(len(a_list)):\n",
    "        z_decoupling_1[i] = z_decoupling(a_list[i], f, (M_halo_0[i]+M_PBH))\n",
    "        M_halo_1 = M_halo(z_decoupling_1, (M_PBH))\n",
    "\n",
    "    z_decoupling_2 = np.zeros(len(a_list))\n",
    "    M_halo_2 = np.zeros(len(a_list))\n",
    "    for i in range(len(a_list)):\n",
    "        z_decoupling_2[i] = z_decoupling(a_list[i], f, (M_halo_1[i]+M_PBH))\n",
    "        M_halo_2 = M_halo(z_decoupling_2, (M_PBH))\n",
    "\n",
    "    z_decoupling_3 = np.zeros(len(a_list))\n",
    "    z_decoupling_check = np.zeros(len(a_list))\n",
    "    M_halo_3 = np.zeros(len(a_list))\n",
    "    for i in range(len(a_list)):\n",
    "        z_decoupling_3[i] = z_decoupling(a_list[i], f, (M_halo_2[i]+M_PBH))\n",
    "        M_halo_3 = M_halo(z_decoupling_3, (M_PBH))\n",
    "        z_decoupling_check[i] = (1. + z_eq) / (1./3 * bigX(x_of_a(a_list[i], 0.01, (M_halo_3[i]+M_PBH)), f, (M_halo_3[i]+M_PBH))/(0.85*0.01)) - 1.\n",
    "    \n",
    "    r_list = r_trunc(z_decoupling_3, M_PBH)\n",
    "    rtr_interp = interp1d(a_list, r_list)\n",
    "    \n",
    "    return rtr_interp\n",
    "\n",
    "def CalcTruncRadius(ai, f, M_PBH):\n",
    "    \n",
    "    z_decoupling_0 = z_decoupling(ai, f, M_PBH)\n",
    "    M_halo_0 = M_halo(z_decoupling_0, M_PBH)\n",
    "\n",
    "    z_decoupling_1 = z_decoupling(ai, f, (M_halo_0+M_PBH))\n",
    "    M_halo_1 = M_halo(z_decoupling_1, (M_PBH))\n",
    "\n",
    "    z_decoupling_2 = z_decoupling(ai, f, (M_halo_1+M_PBH))\n",
    "    M_halo_2 = M_halo(z_decoupling_2, (M_PBH))\n",
    "\n",
    "    z_decoupling_3 = z_decoupling(ai, f, (M_halo_2+M_PBH))\n",
    "    M_halo_3 = M_halo(z_decoupling_3, (M_PBH))\n",
    "\n",
    "    r_list = r_trunc(z_decoupling_3, M_PBH)\n",
    "    return r_list\n",
    "\n",
    "def rho(r, r_tr, M_PBH, gamma=3.0/2.0):\n",
    "    x = r/r_tr\n",
    "    A = (3-gamma)*M_PBH/(4*np.pi*(r_tr**gamma)*(r_eq(M_PBH)**(3-gamma)))\n",
    "    if (x <= 1):\n",
    "        return A*x**(-gamma)\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def Menc(r, r_tr, M_PBH, gamma=3.0/2.0):\n",
    "    x = r/r_tr\n",
    "    if (x <= 1):\n",
    "        return M_PBH*(1+(r/r_eq(M_PBH))**(3-gamma))\n",
    "    else:\n",
    "        return M_PBH*(1+(r_tr/r_eq(M_PBH))**(3-gamma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful cosmological functions\n",
    "\n",
    "def Hubble(z):\n",
    "    return H0_peryr*np.sqrt(Omega_L + Omega_m*(1+z)**3 + Omega_r*(1+z)**4)\n",
    "\n",
    "def Hubble2(z):\n",
    "    return H0*np.sqrt(Omega_L + Omega_m*(1+z)**3 + Omega_r*(1+z)**4)\n",
    "\n",
    "def HubbleLaw(age):\n",
    "    return H0_peryr*age\n",
    "\n",
    "def rho_z(z):\n",
    "    return 3.0*Hubble2(z)**2/(8*np.pi*G_N)\n",
    "\n",
    "def t_univ(z):\n",
    "    integ = lambda x: 1.0/((1+x)*Hubble(x))\n",
    "    return quad(integ, z, np.inf)[0]\n",
    "\n",
    "def Omega_PBH(f):  \n",
    "    return f*Omega_DM\n",
    "\n",
    "rho_critical = 3.0*H0**2/(8.0*np.pi*G_N_Mpc) #Solar masses per Mpc^3\n",
    "\n",
    "def n_PBH(f, M_PBH): \n",
    "    return (1e3)**3*rho_critical*Omega_PBH(f)/M_PBH #PBH per Gpc^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability distributions\n",
    "\n",
    "def j_X(x, f, M_PBH):\n",
    "    return bigX(x, f, M_PBH)*0.5*(1+sigma_eq**2/(0.85*f)**2)**0.5\n",
    "\n",
    "def P_j(j, x, f, M_PBH):\n",
    "    y = j/j_X(x, f, M_PBH)\n",
    "    return (y**2/(1+y**2)**(3.0/2.0))/j\n",
    "\n",
    "def P_a_j(a, j, f, M_PBH):\n",
    "    \n",
    "    xval = x_of_a(a, f, M_PBH)\n",
    "    X = bigX(xval, f, M_PBH)\n",
    "    xb = xbar(f, M_PBH)\n",
    "    measure = (3.0/4.0)*(a**-0.25)*(0.85*f/(alpha*xb))**0.75\n",
    "    return P_j(j, xval, f, M_PBH)*np.exp(-X)*measure\n",
    "\n",
    "def P_a_j_withHalo(a, j, f, M_PBH):\n",
    "    \n",
    "    xval = x_of_a(a, f, M_PBH, withHalo = True)\n",
    "    X = bigX(xval, f, M_PBH)\n",
    "    xb = xbar(f, M_PBH)\n",
    "    \n",
    "    measure = (3.0/4.0)*(a**-0.25)*(0.85*f/(alpha*xb))**0.75    \n",
    "    measure *= ((M_PBH + M_halo(a, M_PBH))/M_PBH )**(3./4.)\n",
    "    \n",
    "    return P_j(j, xval, f, M_PBH)*np.exp(-X)*measure\n",
    "\n",
    "def j_of(z,a, M_PBH):\n",
    "    Q = (3.0/170.0)*(G_N*M_PBH)**-3\n",
    "    return (  (-(z/H0_peryr) + ageUniverse)/(Q*a**4.) )**(1./7.)\n",
    "\n",
    "def P_la_lj(la,lj, f, M_PBH):\n",
    "    j = 10.**lj\n",
    "    a = 10.**la\n",
    "    return P_a_j(a, j, f, M_PBH)*a*j*(np.log(10)**2) #/Norm1\n",
    "\n",
    "def P_la_lj_withHalo(la, lj, f, M_PBH):\n",
    "    j = 10**lj\n",
    "    a = 10**la\n",
    "    return P_a_j_withHalo(a, j, f, M_PBH)*a*j*(np.log(10)**2) #/Norm2\n",
    "\n",
    "def t_coal(a, e, M_PBH):\n",
    "    Q = (3.0/170.0)*(G_N*M_PBH)**(-3) # s^6 pc^-3 km^-6\n",
    "    tc = Q*a**4*(1-e**2)**(7.0/2.0) #s^6 pc km^-6\n",
    "    tc *= 3.086e+13 #s^6 km^-5\n",
    "    tc *= (3e5)**5 #s\n",
    "    return tc/(60*60*24*365) #in years\n",
    "\n",
    "def j_coal(a, t, M_PBH):\n",
    "    Q = (3.0/170.0)*(G_N*M_PBH)**-3 # s^6 pc^-3 km^-6\n",
    "    tc = t*(60*60*24*365)\n",
    "    tc /= (3e5)**5\n",
    "    tc /= 3.086e+13\n",
    "    return (tc/(Q*a**4))**(1.0/7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF plot for M_PBH = 30Msun and f_PHB = 0.01\n",
    "\n",
    "M_PBH_ref = 30.\n",
    "f_ref  = 0.01\n",
    "\n",
    "amin = 5.e-5\n",
    "amax = a_max(f_ref, M_PBH_ref)\n",
    "\n",
    "P1 = lambda y,x,f,M_PBH: P_a_j(x, y, f, M_PBH)\n",
    "Norm1 =  dblquad(P1, amin, amax, lambda x: 0,  lambda x: 1, args=(f_ref, M_PBH_ref), epsrel=1e-20)[0]\n",
    "\n",
    "a_list = np.logspace(-5, np.log10(amax*1.5), 501)\n",
    "j_list = np.logspace(-5, -2, 501)\n",
    "\n",
    "a_grid, j_grid = np.meshgrid(a_list, j_list, indexing='xy')\n",
    "e_grid = np.sqrt(1-j_grid**2)\n",
    "\n",
    "P_a_j_vec = np.vectorize(P_a_j, excluded=(2,3))\n",
    "\n",
    "pl.figure(figsize=(7,6))\n",
    "\n",
    "cf = pl.contourf(a_grid,j_grid, np.log10(P_a_j_vec(a_grid, j_grid, f_ref, M_PBH_ref)/Norm1), cmap=\"Blues\")\n",
    "pl.colorbar(cf,label=r\"$\\log_{10}\\left(P(a, j)/\\mathrm{pc}^{-1} \\right)$\")\n",
    "\n",
    "CS = pl.contour(a_grid, j_grid, t_coal(a_grid, e_grid, M_PBH_ref)/(1e9), levels=[0.1,13.0,1000.0],colors='DarkRed' )\n",
    "\n",
    "pl.clabel(CS, levels=[13.0],  # label every second level\n",
    "           inline=1,\n",
    "           fmt='    %1.f    ',\n",
    "           fontsize=16,\n",
    "            manual=([0.018, 0.003],))\n",
    "\n",
    "pl.clabel(CS, levels=[1000.],  # label every second level\n",
    "           inline=1,\n",
    "           fmt='    %1.f    ',\n",
    "           fontsize=16,\n",
    "            manual=([0.045, 0.006],))\n",
    "\n",
    "pl.clabel(CS, levels=[0.1],  # label every second level\n",
    "           inline=1,\n",
    "           #fmt='$t_\\\\mathrm{merge}$=%1.1f Gyr$\\,$ ',\n",
    "           fmt='    %1.1f Gyr$\\,$    ',\n",
    "           fontsize=16,\n",
    "            manual=([0.005, 0.001],))\n",
    "\n",
    "pl.xlabel(\"Semi-major axis, $a/\\mathrm{pc}$\")\n",
    "pl.ylabel(\"Angular momentum, $j = \\sqrt{1-e^2}$\")\n",
    "pl.title(r\"$M_\\mathrm{PBH} = \" + str(int(M_PBH_ref)) + \"\\,M_\\odot$, $f = \" + str(f_ref) + \"$\",fontsize=18)\n",
    "\n",
    "pl.axvline(a_max(0.01, 30.), linestyle='--', color='k')\n",
    "\n",
    "pl.xlim(1.e-4, 0.1)\n",
    "pl.ylim(1.e-4, 0.01)\n",
    "pl.xscale(\"log\")\n",
    "pl.yscale(\"log\")\n",
    "\n",
    "pl.text(0.032, 0.0002,r\"a$_{\\rm max}$\",color='black',fontsize=14.0)\n",
    "\n",
    "pl.savefig(\"PDF.pdf\",bbox_inches=\"tight\")\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMAPPING PRESCRIPTION\n",
    "\n",
    "def calcBindingEnergy(r_tr, M_PBH):\n",
    "    \n",
    "    integ = lambda r: Menc(r, r_tr, M_PBH)*rho(r, r_tr, M_PBH)*r\n",
    "    return -G_N*4*np.pi*quad(integ,1e-8, 1.0*r_tr, epsrel=1e-3)[0]\n",
    "\n",
    "def getBindingEnergy(r_tr, f, M_PBH):\n",
    "    \n",
    "    global current_MPBH, Ubind_interp, rtr_interp\n",
    "    \n",
    "    if ((M_PBH - current_MPBH)**2 >1e-3 or Ubind_interp == None):\n",
    "        \n",
    "        current_MPBH = M_PBH\n",
    "        #print(\"   Tabulating binding energy and truncation radius (M_PBH = \" + str(M_PBH) +\")...\")\n",
    "        \n",
    "        rtr_vals = np.logspace(np.log10(1e-8), np.log10(1.0*r_eq(M_PBH)),500)\n",
    "        Ubind_vals = np.asarray([calcBindingEnergy(r1, M_PBH) for r1 in rtr_vals])\n",
    "        Ubind_interp = interp1d(rtr_vals, Ubind_vals)\n",
    "        \n",
    "        rtr_interp = GetRtrInterp(f, M_PBH)\n",
    "        \n",
    "    return Ubind_interp(r_tr) \n",
    "\n",
    "\n",
    "def calc_af(ai, f, M_PBH):\n",
    "    \n",
    "    global current_MPBH, rtr_interp, Ubind_interp\n",
    "    \n",
    "    if ((M_PBH - current_MPBH)**2 > 1e-3 or rtr_interp == None):\n",
    "        \n",
    "        current_MPBH = M_PBH\n",
    "       \n",
    "        rtr_vals = np.logspace(np.log10(1.e-8), np.log10(1.0*r_eq(M_PBH)), 500)\n",
    "        Ubind_vals = np.asarray([calcBindingEnergy(r1, M_PBH) for r1 in rtr_vals])\n",
    "        Ubind_interp = interp1d(rtr_vals, Ubind_vals)\n",
    "        \n",
    "        rtr_interp = GetRtrInterp(f, M_PBH)\n",
    "    \n",
    "    #r_tr = CalcTruncRadius(ai, M_PBH)\n",
    "    if (rtr_interp == None):\n",
    "        print(\"warning! no interpolation function\")\n",
    " \n",
    "    r_tr = rtr_interp(ai)\n",
    "\n",
    "    Mtot = Menc(r_tr, r_tr, M_PBH)\n",
    "    #print Mtot\n",
    "    U_orb_before = -G_N*(Mtot**2)/(2.0*ai)\n",
    "    \n",
    "    if (r_tr > r_eq(M_PBH)):\n",
    "        Ubind =  getBindingEnergy(r_eq(M_PBH), f, M_PBH)\n",
    "    else:\n",
    "        #print r_tr, r_eq(M_PBH)\n",
    "        Ubind = getBindingEnergy(r_tr, f, M_PBH)\n",
    "        \n",
    "    return -G_N*M_PBH**2*0.5/(U_orb_before + 2.0*Ubind)\n",
    "\n",
    "\n",
    "def calc_jf(ji, ai, f, M_PBH):\n",
    "    \n",
    "    af = calc_af(ai, f, M_PBH)\n",
    "    return ji*np.sqrt(ai/af)\n",
    "\n",
    "\n",
    "def calc_Tf(Ti, ai, f, M_PBH):\n",
    "    \n",
    "    af = calc_af(ai, f, M_PBH)\n",
    "    return Ti*np.sqrt(af/ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin_sampling = 1.e8\n",
    "tmax_sampling = 1.e11\n",
    "\n",
    "def lnprior(theta, M_PBH, a1, a2):    \n",
    "    la, lj = theta\n",
    "    a = 10**la\n",
    "    j = 10**lj\n",
    "    \n",
    "    if (j > 1):\n",
    "        return -np.inf\n",
    "    \n",
    "    if (a < a1 or a > a2):\n",
    "        return -np.inf\n",
    "        \n",
    "    t = t_coal(a, np.sqrt(1-j**2), M_PBH=M_PBH)\n",
    "    if (t < tmin_sampling or t > tmax_sampling):\n",
    "        return -np.inf\n",
    "    \n",
    "    return 0\n",
    "\n",
    "#Log-probability\n",
    "def lnprob(theta, f, M_PBH, PDF, a1, a2):\n",
    "    lp = lnprior(theta, M_PBH, a1, a2)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    la, lj = theta\n",
    "    \n",
    "    #print la, lj, PDF(la, lj, f, M_PBH)\n",
    "    \n",
    "    return lp + np.log(PDF(la, lj, f, M_PBH))\n",
    "\n",
    "#Sampler\n",
    "#PDF should be a function of the form P_la_lj(la, lj, f, M_PBH)\n",
    "#a1 and a2 are the desired ranges for a\n",
    "def GetSamples_MCMC(N_samps, PDF, a1, a2, f, M_PBH):\n",
    "    \n",
    "    print(\"This is GetSamples_MCMC from a1 = \", a1, \" to a2 = \", a2)\n",
    "    \n",
    "    ndim, nwalkers = 2, 100\n",
    "    \n",
    "    a0 = np.sqrt(a1*a2)\n",
    "    j0 = j_coal(a0, 13e9, M_PBH)\n",
    "    \n",
    "    #print a0, j0\n",
    "\n",
    "    p0 = [[np.log10(a0), np.log10(j0)] + 0.01*np.random.rand(ndim) for i in range(nwalkers)]\n",
    "    #print p0\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[f, M_PBH,PDF, a1, a2])\n",
    "    sampler.run_mcmc(p0, N_samps)\n",
    "    \n",
    "    samples = sampler.chain[:, 1000:, :].reshape((-1, ndim))\n",
    "    stride = 10\n",
    "    print(\"   Generated \", len(samples[::stride,:]), \"samples...\")\n",
    "    return samples[::stride,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the rate from sampled and remapped Kamionkowski distribution - Analytical\n",
    "\n",
    "def P_t_integ(a, t, f, M_PBH, withHalo):\n",
    "        \n",
    "    c = 3.e5 #km/s\n",
    "    Q = (c**6)*(3.0/170.0)*(G_N*M_PBH)**-3 # pc^-3\n",
    "    t_pc = t*(60*60*24*365)*c*3.24078e-14 #Time in years -> Time in parsec    \n",
    "    ecc = np.sqrt(1-(t_pc*1.0/(Q*a**4))**(2.0/7.0))\n",
    "    j_ecc = np.sqrt(1. - ecc**2.)\n",
    "    \n",
    "    P1 = 1.\n",
    "    if (withHalo == False):\n",
    "        P1 = P_a_j(a, j_ecc, f, M_PBH)\n",
    "    else:\n",
    "        P1 = P_a_j_withHalo(a, j_ecc, f, M_PBH)\n",
    "    \n",
    "    djdt = j_ecc/(7*t)\n",
    "    return P1*djdt\n",
    "\n",
    "#Time in years\n",
    "def P_t_of_z_analytical(z, f, M_PBH, withHalo):\n",
    "    \n",
    "    t = t_univ(z)\n",
    "        \n",
    "    avals = np.logspace(np.log10(amin), np.log10(amax), 101) #pc\n",
    "    test = np.asarray([P_t_integ(a, t, f, M_PBH, withHalo) for a in avals])\n",
    "    \n",
    "    integr = np.trapz(test, avals, withHalo)\n",
    "\n",
    "    return integr\n",
    "\n",
    "def P_of_t_analytical(t, f, M_PBH, withHalo): \n",
    "        \n",
    "    avals = np.logspace(np.log10(amin), np.log10(amax), 101) #pc\n",
    "    test = np.asarray([P_t_integ(a, t, f, M_PBH, withHalo) for a in avals])\n",
    "    \n",
    "    integr = np.trapz(test, avals)\n",
    "\n",
    "    return integr\n",
    "\n",
    "###########################################################################\n",
    "\n",
    "t_vec = np.logspace(np.log10(tmin_sampling), np.log10(tmax_sampling), 1000)\n",
    "P_true = np.asarray([P_of_t_analytical(t_, f_ref, M_PBH_ref, withHalo=False) for t_ in t_vec])\n",
    "P_true_withHalo = np.asarray([P_of_t_analytical(t_, f_ref, M_PBH_ref, withHalo=True) for t_ in t_vec])\n",
    "int_analytical = np.trapz(P_true, t_vec)\n",
    "int_analytical_withHalo = np.trapz(P_true_withHalo, t_vec)\n",
    "\n",
    "# Example: 20 and 40 Msun\n",
    "#integrand_20 = lambda x: n_PBH(f_ref, 30.)*sens_20Msun(x)*P_t_of_z_analytical(x, f_ref, 30., withHalo=False) # Gpc^(-3) * Gpc^3 yr * yr^(-1)\n",
    "#integrand_40 = lambda x: n_PBH(f_ref, 30.)*sens_40Msun(x)*P_t_of_z_analytical(x, f_ref, 30., withHalo=False)\n",
    "#N_20 = quad(integrand_20, 0, 0.7)[0]\n",
    "#N_40 = quad(integrand_40, 0, 0.7)[0]\n",
    "#N_20_flat = quad(sens_20Msun, 0, 0.7)[0]\n",
    "#N_40_flat = quad(sens_40Msun, 0, 0.7)[0]\n",
    "#print(\"Analytical Merger Rate [Gpc^-3 yr^-1] for 20 and 40 Msun:\", N_20/N_20_flat,\" - \",N_40/N_40_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nm = 3\n",
    "Nf = 19\n",
    "Nsamples = 2**16\n",
    "print(Nsamples)\n",
    "\n",
    "f_vec = np.logspace(-4.,-1., Nf)\n",
    "m_vec = np.array([10., 30., 100.])\n",
    "rate_vec = np.zeros((Nm,Nf))\n",
    "rate_remapped_vec = np.zeros((Nm,Nf))\n",
    "\n",
    "for i_m in range(Nm):\n",
    "    \n",
    "    print\n",
    "    print(\"*** M = \", m_vec[i_m])\n",
    "    print\n",
    "    \n",
    "    current_file = \"rate_averaged_\" + str(m_vec[i_m]) + \".txt\"\n",
    "    out_f = open(current_file, 'w')\n",
    "    \n",
    "    for i_f in range(Nf):    \n",
    "        \n",
    "        counter_today = 0\n",
    "    \n",
    "        print(\"*** f = \", f_vec[i_f])\n",
    "\n",
    "        print(\"Sampling PDF... \")\n",
    "        print(\"amax = \", a_max_with_Halo(f_vec[i_f], m_vec[i_m]))\n",
    "        samples_MCMC = GetSamples_MCMC(Nsamples, P_la_lj_withHalo, amin, a_max_with_Halo(f_vec[i_f], m_vec[i_m]), f_vec[i_f], m_vec[i_m])\n",
    "        print(\"...Done\")\n",
    "\n",
    "        la_vals_all = samples_MCMC[:,0]\n",
    "        print(\"max a from GetSamples = \", 10.**(np.amax(la_vals_all)))\n",
    "        lj_vals_all = samples_MCMC[:,1]\n",
    "        z_vals_all = np.zeros(Nsamples)\n",
    "        t_vals_all = np.zeros(Nsamples)\n",
    "\n",
    "        z_vals_remapped = np.zeros(Nsamples)\n",
    "        t_vals_remapped = np.zeros(Nsamples)\n",
    "\n",
    "        for ind in range(Nsamples):  \n",
    "            \n",
    "            a_ = 10.**(la_vals_all[ind])\n",
    "            j_ = 10.**(lj_vals_all[ind])\n",
    "            e_ = np.sqrt(1. -  (j_**2.))\n",
    "            current_t_coal = t_coal(a_, e_, m_vec[i_m]) \n",
    "            current_z = H0_peryr * (ageUniverse - current_t_coal)\n",
    "            \n",
    "            if ((current_z < 0.) or (current_z > 1.0)):\n",
    "                current_z = 1.e10 # just some big number\n",
    "            \n",
    "            t_vals_all[ind] = current_t_coal        \n",
    "            z_vals_all[ind] = current_z\n",
    "            remapped_a = calc_af(a_, f_vec[i_f], m_vec[i_m])\n",
    "            remapped_j = calc_jf(j_, a_, f_vec[i_f], m_vec[i_m])\n",
    "            remapped_e = np.sqrt(1. -  (remapped_j**2.))\n",
    "            remapped_t_coal = t_coal(remapped_a, remapped_e, m_vec[i_m]) \n",
    "            remapped_z = H0_peryr * (ageUniverse - remapped_t_coal)\n",
    "            \n",
    "            if ((remapped_z >= 0.) and (remapped_z <= 1.0)):\n",
    "                counter_today += 1\n",
    "            \n",
    "            z_vals_remapped[ind] = remapped_z\n",
    "            t_vals_remapped[ind] = remapped_t_coal\n",
    "\n",
    "        bins_t = np.logspace(8, 11, 101)\n",
    "        logBins_t = np.linspace(8, 11, 101)\n",
    "        bins_t_centres = np.sqrt(bins_t[:-1]*bins_t[1:])\n",
    "        \n",
    "        nt_remapped, bins_t_remapped, patches = pl.hist(np.log10(t_vals_remapped), bins=logBins_t, normed=True, alpha=0.85)\n",
    "        nt_remapped_normalized = nt_remapped/(bins_t_centres*np.log(10))        \n",
    "        \n",
    "        P_t_remapped_numerical = interp1d(bins_t_centres, nt_remapped_normalized, kind='linear')\n",
    "        \n",
    "        t_vec = np.logspace(np.log10(tmin_sampling), np.log10(tmax_sampling), 1000)\n",
    "        P_true_withHalo = np.asarray([P_of_t_analytical(t_, f_vec[i_f], m_vec[i_m], withHalo=True) for t_ in t_vec])\n",
    "        int_analytical_withHalo = np.trapz(P_true_withHalo, t_vec)\n",
    "\n",
    "        my_integrand = lambda x: P_t_remapped_numerical(t_univ(x)) \n",
    "        my_integral = quad(my_integrand, 0.0, 1.0)[0] / 1.0\n",
    "\n",
    "        rate_vec[i_m, i_f] = n_PBH(f_vec[i_f], m_vec[i_m]) * P_t_of_z_analytical(0., f_vec[i_f], m_vec[i_m], withHalo=False)                \n",
    "        rate_remapped_vec[i_m, i_f] = n_PBH(f_vec[i_f],m_vec[i_m]) * my_integral * int_analytical_withHalo\n",
    "\n",
    "        print(\"fraction of binaries that merge today = \", P_t_remapped_numerical(t_univ(0.)), \"; averaged =  \",  my_integral)\n",
    "        \n",
    "        current_str = str(f_vec[i_f]) + \"\\t\" + str(rate_vec[i_m, i_f]) + \"\\t\" + str(rate_remapped_vec[i_m, i_f])+\"\\n\"\n",
    "        print(current_str)\n",
    "        out_f.write(current_str)\n",
    "        \n",
    "    out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nm = 3\n",
    "Nf_analytical = 100\n",
    "f_vec_analytical = np.logspace(-5.,0., Nf_analytical)\n",
    "m_vec = np.array([10., 30., 100.])\n",
    "rate_vec_analytical = np.zeros((Nm,Nf_analytical))\n",
    "print(f_vec_analytical)\n",
    "\n",
    "for i_m in range(Nm):\n",
    "    \n",
    "    print(\"*** M = \", m_vec[i_m])\n",
    "        \n",
    "    for i_f in range(Nf_analytical):    \n",
    "        \n",
    "        my_integrand_an = lambda x: P_t_of_z_analytical(x, f_vec_analytical[i_f], m_vec[i_m], withHalo=False)\n",
    "        my_integral_an = quad(my_integrand_an, 0.0, 1.0)[0] / 1.0 \n",
    "    \n",
    "        rate_vec_analytical[i_m, i_f] = n_PBH(f_vec_analytical[i_f], m_vec[i_m]) * my_integral_an # P_t_of_z_analytical(0., f_vec_analytical[i_f], m_vec[i_m], withHalo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "print(rate_vec)\n",
    "print(rate_remapped_vec)\n",
    "\n",
    "mpl.rc('font', **{'size'   : 18})\n",
    "\n",
    "\n",
    "pl.figure(figsize=(7,6))\n",
    "\n",
    "col = np.array([\"red\",\"green\",\"blue\"])\n",
    "\n",
    "for iM in range(Nm):\n",
    "    \n",
    "    current_file = \"rate_smooth_averaged_\" \n",
    "    if (iM==0):\n",
    "        lab=\"10 M$_{\\odot}$\"\n",
    "        current_file += (str(m_vec[iM]) + \".txt\")\n",
    "    if (iM==1):\n",
    "        lab=\"30 M$_{\\odot}$\"\n",
    "        current_file += (str(m_vec[iM]) + \".txt\")\n",
    "    if (iM==2):\n",
    "        lab=\"100 M$_{\\odot}$\"\n",
    "        current_file += (str(m_vec[iM]) + \".txt\")\n",
    "        \n",
    "    print(\"Reading \",current_file)        \n",
    "    \n",
    "    f_vec, rate_remapped_vec = np.loadtxt(current_file, usecols=(0, 2), unpack=True)  \n",
    "        \n",
    "    pl.loglog(f_vec_analytical, rate_vec_analytical[iM,:], linewidth=1.5, ls=\"--\", label=lab, color=col[iM])\n",
    "    pl.loglog(f_vec, rate_remapped_vec, linewidth=1.5, ls=\"-\", color=col[iM])\n",
    "    \n",
    "pl.xlim(1.e-4,1.)\n",
    "pl.ylim(.1,1.e6)\n",
    "\n",
    "pl.fill_between(f_vec_analytical, 10., 200.0, color=\"lightGrey\")\n",
    "    \n",
    "pl.xlabel(r\"$f_{\\rm PBH}$\")\n",
    "pl.ylabel(r\"Merger rate   [Gpc$^{-3}$ yr$^{-1}$]\")\n",
    "pl.tight_layout()\n",
    "\n",
    "pl.legend(loc='lower right', frameon=False)\n",
    "pl.savefig(\"moneyPlot_smooth.pdf\", format='pdf')\n",
    "\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
